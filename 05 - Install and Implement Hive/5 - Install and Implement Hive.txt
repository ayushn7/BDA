# 1. Configure and implement Hive 
==================================================================================================

# Remove hive, if it is already present
sudo rm -r -f /usr/local/hive

# 1. Login to hadoop user if not already logged in
su hduser

# Start hadoop services
ssh localhost
/usr/local/hadoop/sbin/start-all.sh
jps

# 2. Go to "/usr/local" & Extract the hive tar file
cd /usr/local
sudo tar xvzf /home/vivekn7/Downloads/apache-hive-3.1.2-bin.tar.gz 
sudo mv apache-hive-3.1.2-bin/ hive
sudo chmod 777 hive

# 3. Add the HIVE_HOME path in the bashrc file.
cd /home/hduser
sudo nano ~/.bashrc

# Add following lines 
export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$HIVE_HOME/bin

source ~/.bashrc

# 4. Change the directory to "/usr/local/hive/bin" and add the following lines in hive-config.sh
cd /usr/local/hive/bin     
sudo nano hive-config.sh

export HADOOP_HOME=/usr/local/hadoop

# 5. Hive is installed now, but we need to first create some directories in HDFS for Hive to store its data

hdfs dfs -mkdir /tmp
hdfs dfs -chmod g+w /tmp
hdfs dfs -mkdir -p /user/hive/warehouse
hdfs dfs -chmod g+w /user/hive/warehouse
sudo chmod 777 /usr/local/hive/

# 6. Now we need to initialize the derby database.
cd /usr/local/hive/
cd /$HIVE_HOME/bin

$HIVE_HOME/bin/schematool -initSchema -dbType derby

# 7. There is compatibility error between Hadoop and Hive guava versions.
Note: To fix the "NoSuchMethodError", Locate the guava jar file in the Hive lib directory & Remove the guava jar file from "/hive/lib"
cd ..
sudo rm lib/guava-19.0.jar

# Copy the guava jar from hadoop lib to hive lib directory
sudo cp $HADOOP_HOME/share/hadoop/common/lib/guava-27.0-jre.jar /usr/local/hive/lib/

# Once copied, Use the schematool command once again to initiate the Derby database

cd /$HIVE_HOME
schematool  -initSchema -dbType derby

# 8. Start the Hive command-line interface by using the ‘hive’ command
hive
show databases;

# 9. Create a database and a table in a hive
create database company;
show databases;
use company;

create table employees (id int, name string, country string, department string, salary int) row format delimited fields terminated by ' ';

# 10. Load the data into a table from a file
sudo nano employees.txt

# Enter few rows without spaces
1 Vivek India Google 500000
2 Ayush Canada L&T 700000
3 Anchita India Tata 300000
4 Rahul USA TCS 450000
5 Manish Japan Apple 500000

load data local inpath "/home/hduser/employees.txt" into table employees;

# 11. Display the loaded data
select * from employees;

# 12. Exit hive using this command;
exit;

Note : To fix the Function "NUCLEUS_ASCII" Error 
mv metastore_db metastore_db.tmp

================================================================================================
