# Practical 4 : Implement PIG
==================================================================================================

# 1. Login to hadoop user if not already logged in
su hduser

# Start hadoop services
ssh localhost
/usr/local/hadoop/sbin/start-all.sh
jps

# 2. Go to "/usr/local" 
cd /usr/local

# 3. Extract the pig tar file
sudo tar xzvf /home/vivekn7/Downloads/pig-0.17.0.tar.gz 
sudo mv pig-0.17.0/ pig

# 4. Add the Pig environment variables in bashrc & 
# Check the pig version to verify the installation.
sudo nano ~/.bashrc     

# Add the following lines
export PIG_HOME=/usr/local/pig
export PATH=$PATH:$PIG_HOME/bin
export PIG_CLASSPATH=$HADOOP_HOME/conf

# Execute the changes
source ~/.bashrc

# 5. Create a database file
sudo nano products.txt

# Enter some text (without spaces)
1,phone,45,mumbai,2023
2,laptop,44,pune,2022

# Save & Exit

# 6. Run the pig in Local mode (pig can access data in local file system, Eg., the product file) 
# Start pig using following command:
pig -x local

product = LOAD 'products.txt' USING PigStorage(',');
dump product;
quit;

# 7. Running in HDFS mode (pig can access data on HDFS)
# First we need to move products.txt to HDFS
hdfs dfs -put /usr/local/products.txt /

# 8. Start pig using pig command
pig

product = LOAD 'hdfs://localhost:54310/products.txt' USING PigStorage(',');
dump product;
STORE product INTO '/output.txt';
quit;

==================================================================================================
